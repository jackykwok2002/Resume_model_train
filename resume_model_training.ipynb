{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "resume_model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUd5GqZScLjHzj7MUNIEzl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackykwok2002/Resume_model_train/blob/main/resume_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8vzKEg-WIDP"
      },
      "source": [
        "import pandas as pd # load and manipulate data and for One-Hot Encoding\n",
        "import numpy as np # calculate the mean and standard deviation\n",
        "import re \n",
        "import xgboost as xgb # XGBoost stuff\n",
        "from sklearn.model_selection import train_test_split # split  data into training and testing sets\n",
        "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer # for scoring during cross validation\n",
        "from sklearn.model_selection import GridSearchCV # cross validation\n",
        "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
        "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OrdinalEncoder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIv1EjzfWP1t"
      },
      "source": [
        "df = pd.read_csv(\"sdfz_resume.csv\")\n",
        "df = df.drop(['原始文本','姓名','投递时间','电话','邮箱','岗位','工作经历'], axis=1) #temporarily drop 工作经历\n",
        "df = df.drop_duplicates() "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyaR0319yp9c",
        "outputId": "cb6f70b3-df13-4dad-9b9c-df97708ee863"
      },
      "source": [
        "global locations\n",
        "filter_words = ['深圳','上海','厦门','北京','南山区', '（实习）','nan', '(实习)', '—', '冯德宇', '李涵', '廖舸凯', '张育霖', ' ', '张锴旺', '实习生', '实习']\n",
        "\n",
        "replace_words = {\n",
        "    'ai研究员/ai工程师':'ai工程师',\n",
        "    'hr（招聘方向）':'hr',\n",
        "    'ui':'ui设计师',\n",
        "    '前端开发':'前端工程师',\n",
        "    '前端开发工程师':'前端工程师',\n",
        "    '后台工程师':'后台开发',\n",
        "    '后台开发工程师':'后台开发',\n",
        "    '后端':'后台开发',\n",
        "    '爬虫后端':'爬虫后端工程师',\n",
        "    '市场营销bd':'市场营销',\n",
        "    '高级后台开发工程师':'高级后台工程师'\n",
        "}\n",
        "\n",
        "# 将应聘职位过滤\n",
        "def filterJobs(x):\n",
        "  s = str(x[\"应聘职位\"]).lower()\n",
        "  if s == '':\n",
        "    return None\n",
        "  s = s.replace('-','').replace('（','(').replace('）',')')\n",
        "  for word in filter_words:\n",
        "     if word in s:\n",
        "       s = s.replace(word, '')\n",
        "  if s in replace_words:\n",
        "    s = replace_words[s]\n",
        "  return s.strip()\n",
        "\n",
        "df[\"应聘职位\"] = df.apply(filterJobs, axis=1)\n",
        "df[\"应聘职位\"].unique()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['数据分析', '算法工程师(运筹优化方向)', '人工智能算法研究员', '后台开发', '高级后台工程师', '前端工程师',\n",
              "       '项目经理', '算法工程师', '解决方案工程师', '销售经理', '大数据/ai架构工程师',\n",
              "       '行业解决方案高级工程师(后台方向)', 'hr(招聘方向)', '产品经理', '微服务架构师',\n",
              "       '行业解决方案工程师(后台方向)', '自然语言处理算法工程师', '人事行政专员', '搜索算法工程师',\n",
              "       '行业解决方案工程师(运筹优化方向算法)', '智能物流解决方案业务经理', '行业解决方案工程师(机器学习方向)',\n",
              "       '推荐算法工程师', '计算机视觉算法工程师', 'ceo助理', '爬虫后端工程师', '算法工程师(仿真平台方向)',\n",
              "       '算法工程师(决策方向)', '机器学习算法工程师', '行业解决方案工程师(强化学习方向)', '运筹优化产品经理',\n",
              "       '售前工程师', '系统架构师', '强化学习算法工程师', '知识图谱算法工程师', 'ui设计师',\n",
              "       '金融/工业/零售行业高级咨询专家', '运维工程师', '数据中台工程师', '市场营销', '音频算法工程师',\n",
              "       '大数据后台开发工程师', '用户画像工程师', '测试工程师', '大数据研发工程师', '搜索推荐高级研发工程师',\n",
              "       '商务助理', '后端开发工程师(搜索推荐方向)', 'ai工程师', '大数据工程师(搜索推荐方向)', 'python工程师',\n",
              "       '', '会计', '大客户经理', 'hrbp', 'hr', '视觉/运营设计师', '商务总监助理',\n",
              "       '行业研究(解决方案产品助理)', 'ai解决方案工程师', '视觉设计师', '视觉设计师(三维方向)'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOpcuMJtWs-g"
      },
      "source": [
        "# 工作年限转换为Integer\n",
        "def toNumber(x):\n",
        "  if x[\"工作年限\"] is None:\n",
        "    return \n",
        "\n",
        "  s = str(x[\"工作年限\"])\n",
        "\n",
        "  if '毕业' in s:\n",
        "    return 0\n",
        "  elif '1年及以内' in s or '1年以内' in s:\n",
        "    return 0.5\n",
        "  else:\n",
        "    import re\n",
        "    return re.sub(\"[^0-9]\", \"\", s)\n",
        "\n",
        "df[\"工作年限\"] = df.apply(toNumber, axis=1)\n",
        "df['工作年限'] = pd.to_numeric(df['工作年限'])\n",
        "df['工作年限'].unique()\n",
        "\n",
        "# 将学历过滤\n",
        "def filterEducation(x):\n",
        "  if '深圳' in str(x[\"学历\"]):\n",
        "    return None \n",
        "  else:\n",
        "    return x[\"学历\"]\n",
        "\n",
        "df[\"学历\"] = df.apply(filterEducation, axis=1)\n",
        "\n",
        "# 性别过滤\n",
        "def filterSex(x):\n",
        "  if '男' in str(x[\"性别\"]) or '女' in str(x[\"性别\"]):\n",
        "    return x[\"性别\"]\n",
        "  else:\n",
        "    return None\n",
        "\n",
        "df[\"性别\"] = df.apply(filterSex, axis=1)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2od8gzIUhzx7"
      },
      "source": [
        "# 毕业时间\n",
        "def filterGraduation(x):\n",
        "  s = str(x[\"毕业时间\"])\n",
        "  if '-' in s:\n",
        "    s = s.split('-')[0]\n",
        "  if '/' in s:\n",
        "    s = s.split('/')[2]\n",
        "  s = s.replace(\"届\", \"\").replace('级别','').replace('级','').replace('15659420518','0').replace('nan','0')\n",
        "  return s\n",
        "\n",
        "df[\"毕业时间\"] = df.apply(filterGraduation, axis=1)\n",
        "df['毕业时间'] = pd.to_numeric(df['毕业时间'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giPj_93OLjpJ"
      },
      "source": [
        "# Use number to represent schools\n",
        "# 学校转换为数字\n",
        "\n",
        "global school_lst\n",
        "school_lst = list(df['毕业院校'].unique().astype(str).copy())\n",
        "school_lst.sort()\n",
        "\n",
        "df['毕业院校'] = df['毕业院校'].apply(lambda x: school_lst.index(str(x)))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGlCn7y7Xa_1"
      },
      "source": [
        "# 处理“技能”\n",
        "# 转换为list\n",
        "def skillsToList(x):\n",
        "  if str(x[\"技能\"]) == 'nan':\n",
        "    return []\n",
        "  return str(x[\"技能\"]).split(' | ')\n",
        "df[\"技能\"] = df.apply(skillsToList, axis=1)\n",
        "\n",
        "# One Hot Encoded #source:https://stackoverflow.com/questions/45312377/how-to-one-hot-encode-from-a-pandas-column-containing-a-list\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer()\n",
        "df = df.join(pd.DataFrame(mlb.fit_transform(df.pop('技能')),\n",
        "                          columns=mlb.classes_,\n",
        "                          index=df.index))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjoTLOfAmzQd"
      },
      "source": [
        "# Split the Data into Dependent and Independent Variables\n",
        "X = df.drop('应聘职位', axis=1).copy() \n",
        "y = df['应聘职位'].copy().astype(str)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj3WhJPptOaD"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6nHgO_8p71P"
      },
      "source": [
        "# One Hot Encode the rest\n",
        "X_encoded = pd.get_dummies(X, columns=['专业', \n",
        "                                       '学历', \n",
        "                                       '工作地点', \n",
        "                                       '性别',\n",
        "                                       '类别',\n",
        "                                       '应聘渠道'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tL8WKvRU47y6"
      },
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bk74BPP2tg1"
      },
      "source": [
        "# Spliting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size = 0.2, random_state = 1002)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLDedqEa-Ls4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0251ba26-f23e-472d-9017-b115a4cefcfa"
      },
      "source": [
        "clf_xgb = xgb.XGBClassifier(objective='multi:softmax',\n",
        "                            eval_metric=\"logloss\", ## this avoids a warning...\n",
        "                            seed=42, \n",
        "                            use_label_encoder=False)\n",
        "clf_xgb.fit(X_train, \n",
        "            y_train,\n",
        "            verbose=True,\n",
        "            early_stopping_rounds=10,\n",
        "            eval_metric='mlogloss',\n",
        "            eval_set=[(X_test, y_test)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-mlogloss:3.56771\n",
            "Will train until validation_0-mlogloss hasn't improved in 10 rounds.\n",
            "[1]\tvalidation_0-mlogloss:3.32722\n",
            "[2]\tvalidation_0-mlogloss:3.16851\n",
            "[3]\tvalidation_0-mlogloss:3.04333\n",
            "[4]\tvalidation_0-mlogloss:2.94184\n",
            "[5]\tvalidation_0-mlogloss:2.85508\n",
            "[6]\tvalidation_0-mlogloss:2.77776\n",
            "[7]\tvalidation_0-mlogloss:2.7083\n",
            "[8]\tvalidation_0-mlogloss:2.64838\n",
            "[9]\tvalidation_0-mlogloss:2.59392\n",
            "[10]\tvalidation_0-mlogloss:2.54622\n",
            "[11]\tvalidation_0-mlogloss:2.50197\n",
            "[12]\tvalidation_0-mlogloss:2.46135\n",
            "[13]\tvalidation_0-mlogloss:2.4238\n",
            "[14]\tvalidation_0-mlogloss:2.38937\n",
            "[15]\tvalidation_0-mlogloss:2.35832\n",
            "[16]\tvalidation_0-mlogloss:2.32971\n",
            "[17]\tvalidation_0-mlogloss:2.30185\n",
            "[18]\tvalidation_0-mlogloss:2.27799\n",
            "[19]\tvalidation_0-mlogloss:2.2535\n",
            "[20]\tvalidation_0-mlogloss:2.23241\n",
            "[21]\tvalidation_0-mlogloss:2.21134\n",
            "[22]\tvalidation_0-mlogloss:2.19151\n",
            "[23]\tvalidation_0-mlogloss:2.17373\n",
            "[24]\tvalidation_0-mlogloss:2.15676\n",
            "[25]\tvalidation_0-mlogloss:2.14039\n",
            "[26]\tvalidation_0-mlogloss:2.12506\n",
            "[27]\tvalidation_0-mlogloss:2.1109\n",
            "[28]\tvalidation_0-mlogloss:2.09685\n",
            "[29]\tvalidation_0-mlogloss:2.08473\n",
            "[30]\tvalidation_0-mlogloss:2.07192\n",
            "[31]\tvalidation_0-mlogloss:2.06135\n",
            "[32]\tvalidation_0-mlogloss:2.04992\n",
            "[33]\tvalidation_0-mlogloss:2.04047\n",
            "[34]\tvalidation_0-mlogloss:2.03013\n",
            "[35]\tvalidation_0-mlogloss:2.02067\n",
            "[36]\tvalidation_0-mlogloss:2.01084\n",
            "[37]\tvalidation_0-mlogloss:2.00232\n",
            "[38]\tvalidation_0-mlogloss:1.99401\n",
            "[39]\tvalidation_0-mlogloss:1.98661\n",
            "[40]\tvalidation_0-mlogloss:1.97903\n",
            "[41]\tvalidation_0-mlogloss:1.97232\n",
            "[42]\tvalidation_0-mlogloss:1.96567\n",
            "[43]\tvalidation_0-mlogloss:1.95955\n",
            "[44]\tvalidation_0-mlogloss:1.95336\n",
            "[45]\tvalidation_0-mlogloss:1.94797\n",
            "[46]\tvalidation_0-mlogloss:1.94227\n",
            "[47]\tvalidation_0-mlogloss:1.9371\n",
            "[48]\tvalidation_0-mlogloss:1.93235\n",
            "[49]\tvalidation_0-mlogloss:1.92685\n",
            "[50]\tvalidation_0-mlogloss:1.92316\n",
            "[51]\tvalidation_0-mlogloss:1.91882\n",
            "[52]\tvalidation_0-mlogloss:1.91492\n",
            "[53]\tvalidation_0-mlogloss:1.9109\n",
            "[54]\tvalidation_0-mlogloss:1.9065\n",
            "[55]\tvalidation_0-mlogloss:1.90357\n",
            "[56]\tvalidation_0-mlogloss:1.90063\n",
            "[57]\tvalidation_0-mlogloss:1.89723\n",
            "[58]\tvalidation_0-mlogloss:1.89344\n",
            "[59]\tvalidation_0-mlogloss:1.89007\n",
            "[60]\tvalidation_0-mlogloss:1.88704\n",
            "[61]\tvalidation_0-mlogloss:1.88365\n",
            "[62]\tvalidation_0-mlogloss:1.88078\n",
            "[63]\tvalidation_0-mlogloss:1.87826\n",
            "[64]\tvalidation_0-mlogloss:1.87562\n",
            "[65]\tvalidation_0-mlogloss:1.874\n",
            "[66]\tvalidation_0-mlogloss:1.87172\n",
            "[67]\tvalidation_0-mlogloss:1.86965\n",
            "[68]\tvalidation_0-mlogloss:1.86759\n",
            "[69]\tvalidation_0-mlogloss:1.86502\n",
            "[70]\tvalidation_0-mlogloss:1.86239\n",
            "[71]\tvalidation_0-mlogloss:1.8608\n",
            "[72]\tvalidation_0-mlogloss:1.85895\n",
            "[73]\tvalidation_0-mlogloss:1.85735\n",
            "[74]\tvalidation_0-mlogloss:1.85515\n",
            "[75]\tvalidation_0-mlogloss:1.85415\n",
            "[76]\tvalidation_0-mlogloss:1.85264\n",
            "[77]\tvalidation_0-mlogloss:1.85084\n",
            "[78]\tvalidation_0-mlogloss:1.84916\n",
            "[79]\tvalidation_0-mlogloss:1.84782\n",
            "[80]\tvalidation_0-mlogloss:1.84672\n",
            "[81]\tvalidation_0-mlogloss:1.84519\n",
            "[82]\tvalidation_0-mlogloss:1.8434\n",
            "[83]\tvalidation_0-mlogloss:1.8421\n",
            "[84]\tvalidation_0-mlogloss:1.84144\n",
            "[85]\tvalidation_0-mlogloss:1.83962\n",
            "[86]\tvalidation_0-mlogloss:1.83864\n",
            "[87]\tvalidation_0-mlogloss:1.83763\n",
            "[88]\tvalidation_0-mlogloss:1.83695\n",
            "[89]\tvalidation_0-mlogloss:1.8362\n",
            "[90]\tvalidation_0-mlogloss:1.8354\n",
            "[91]\tvalidation_0-mlogloss:1.83427\n",
            "[92]\tvalidation_0-mlogloss:1.83328\n",
            "[93]\tvalidation_0-mlogloss:1.83262\n",
            "[94]\tvalidation_0-mlogloss:1.83215\n",
            "[95]\tvalidation_0-mlogloss:1.83078\n",
            "[96]\tvalidation_0-mlogloss:1.83\n",
            "[97]\tvalidation_0-mlogloss:1.82928\n",
            "[98]\tvalidation_0-mlogloss:1.82862\n",
            "[99]\tvalidation_0-mlogloss:1.82825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, eval_metric='logloss',\n",
              "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
              "              silent=None, subsample=1, use_label_encoder=False, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nadI8OwxKZvn"
      },
      "source": [
        "# save the model to disk\n",
        "import pickle\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(clf_xgb, open(filename, 'wb'))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSBIl5zHKre-",
        "outputId": "75e730db-4917-4cd2-da17-2b084871be67"
      },
      "source": [
        "result = clf_xgb.score(X_test, y_test)\n",
        "print(result)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.46883468834688347\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}